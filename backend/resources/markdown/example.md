# Test-Time Prompt Tuning for Zero-Shot Generalization in Vision-Language Models

## Abstract
- 与训练视觉语言模型(如CLIP)通过适当文本prompt设计在很多下游任务有很好的泛化能力。
- 最近的工作使用下游的训练数据替代手动编辑的prompt
- 但是这样泛化能力会减弱
- test-time prompt tuning(TPT)可以使用单个text prompt样本动态地学习适应prompt。
- 通过使用置信度选择最小化交叉熵，模型可以对每一个测试样本的不同的增广的视图有一致的预测。
- TPT平均提升了CLIP 3.6%在 zero-shot,超过了需要额外特定任务的数据的调优方法。
- 在未见过的类跨数据集泛化的评估上，TPT与最好的使用了额外训练数据的方法效果持平。
## introduction
- 视觉语言模型，CLIP和ALIGN基础模型在视觉方面很强。
- 训练数百万图片-文本对来压缩很宽泛的视觉概念，这样可以使用zero-shot的方法来应用到下游的应用（不需要任何特定任务的数据集）。
- 这是通过合适地设计指示prompt。
### 过程
1. 预设类名"a photo of ..."(dog),
2. CLIP用不同的类描述来测量图片文字的关系来分类图片。
3. 关键在于设计prompt
4. 手写的prompt需要针对特定域的启发，可能不是最优。
#### recent work
1. 通过提议promt调优使用下游的训练数据直接学习prompt。
2. 我们可以使用训练数据用优化模型参数同样的方法来调优prompt
    - 原因是prompt嵌入是模型输入的一部分，对于损失函数也是可微的。
    - 与手写相比，可以找到更好的prompt
    - 但是学习的prompt仅限于对应训练数据的分布和任务，而且可能有限的泛化。
    - 这个方法也需要对训练数据打标签，开销大，且不适合zero-short
---
![TPT](./TPTprocess.png)
- 通过减少边缘熵的办法增广试图来鼓励一直的预测的方法来自适应prompt。
- 引入了置信度选择去过滤掉噪声增强
--- 
### 我们的方法
#### 两条下游任务来探索TPT
- 图片分类和上下文依赖的视觉推理。
- 对每一个任务，都定制一个测试时间调优策略适合任务的本质。
- 不失通用性，使用CLIP作为视觉语言的基座模型。因为设计简单，且应用广泛。
- 使用置信度选择过滤掉噪声增广视图。通过在所有增广的视图最小化边缘熵来实现。
- 丢掉高预测熵的增广图(低置信度)
#### 评估zero-short 用两种图片分类的设置
- 自然分布转移
    - 0-shot提升clip3.6% 与手写prompt相比
    - 与以往的需要额外训练数据的提示优化方法持平
    - 超过存在的few-shot方法5.1%。
- 跨数据集泛化。
    - 对于评估可能未见过数据集的跨数据集泛化，tpt得到了目前最好的没有额外数据和标签few-shot prompt调优的持平的表现。
#### 上下文依赖的视觉推理
Bongard-HOI
- 一个测试样本包括 两套支持图片和一个用于评估的查询托i按。
    - 两套支持图片例证了人类物体交互的确实和出现。
    - 然后模型用来推理查询托i按是否包含潜在的概念。
- 得到这样的测试样本，通过在两个支持集调优prompt的方法去更好的微分来应用TPT。
- 尽管支持集的使用，我们的方法仍然使用是zero-shot视觉推理，因为没有在查询图片的其他概念或者标签在测试时间去更新测试任务的prompt。 
- 最先进的方法，4.1% Bongard-HOI 基线。
### 主要贡献
1. TPT不需要任何训练数据和标签来优化prompt,第一个在单张图片使用zeroshot实现prompt调优。
2. 置信度选择(一个即插即用的tpt模块)应用在图片分类，有利于增广视图的熵的减少
3. 做了在自然分布转移的分类跨数据集泛化和上下文依赖的视觉推理的深入实验。tpt提升了clip在zero-shot的能力，与无promt调优，但需要额外训练数据的方法持平。
## 相关的工作
### 对基础模型的prompting
基础模型使用大尺寸的异构数据训练，其中知识被转移到了不同的的下游任务，通过自然语言处理，计算机视觉等。
- prompt是一个启发式的方法去直接应用基础模型到下游是任务，用zero-shot的方法。
- 但对prompt要求很严格。
- prompt调优提议学习下游的数据的prompt在接下来输入嵌入空间，这样可以提供一个参数高效的来调优基础模型。
- 最初prompt仅仅用在语言模型，接着被用在视觉语言模型和继续学习。
- CoOp将prompt应用到了CLIP。通过调优训练数据集，
CoOp有效提升了CLIP的对应下游任务的表现。
- CoCoOp指出CoOp缺少在非分布数据的泛化，并提议减少问题，通过prompt，基于模型的输入。
- 另一个方法使用无监督的方式，但是需要通过从训练和测试分离的多采样。

### 在数据分布转移下的泛化
对于一个给定了训练数据的模型，分布转换指测试数据和悬链数据的偏移。
- 真实世界偏移，元学习文学，训练集和测试集分离的便宜。
- clip可以使用zero-shot的方法来泛化下游的不同的分布转换的任务。
- 我们的方法旨在提升clip，成为一个更好通用模型，而不是针对特定的下游任务或者特定数据集。
---
- 在这个工作中，使用了一个假设，模型应当有决策边界，在低密度的数据区域
- 基于一致正则化的方法，可以达到这个目的，通过让网络输出变体变成一个小的输入扰动（比如增广）,
- 我们使用了一致性正则化作为测试的prompt调优，用置信度选择模块
### 测试时的优化
挑战：
- 设计一个有效的测试时间的目标函数，
    - 通过增加自监督多任务分支，测试时间训练和它的变体塑造了训练过程。这样在测试时间计算一个优化目标函数也网络也适应了测试样本。
    - TENT提出一个测试时间函数，通过提供最小化熵，这个熵是面向批次预测可能性分布的。这样的一个目标函数不需要依赖特定的训练过程，因此可以应用到广阔的模型范围内。 但是TENT,需要多余一个一个样本去得到一个非平凡的解。
    - 张等人提出绕过多样本的需求，需要使用数据增强。
- 另外一个挑战是更新特征提取同时冻结预测模块
    - 张等人展示了优化整个模块在测试的时候是也可以工作的。
- 我们的任务是解决上面提到的问题。对于参数组的选择，我们优化文本prompt同时完美无缺。我们的动机是避免预训练模型的变形，并且保证预训练模型zero-shot泛化的能力。
## TPT
1. 讨论怎么把CLIP应用到下游，使用zero-shot的方法和手写的prompt。
2. 简单介绍近期的在prompt调优的方法的进步，用在CLIP上的，并且使用下游训练的方法。
3. 引入TPT用于上下文依赖的视觉推理，和它应用的背景知识。
### 背景
- CLIP使用两个平行的编码器
    - 分别将文本和图片映射成一个特征向量。
    - 模型使用对比loss函数，产生相似性，相似性来源于两个向量之间。这样文本和图片在一个特征空间联合了起来。我们使CLIP模型作为F={Ev,Et}.
- 怎么用手写的prompt实现zero-short的clip下游应用。
#### Prompt tuning using downstream training data
#### 上下文以来的视觉推理
上下文依赖的视觉推理，如Bongard_HOI，
- 两套支持图片显示有无人类和物体交互的的概念。
- 模型推测查询图片中是否有潜在的概念。
- 这个任务的每个概念都是一种视觉关系。`c=<s,a,o>`
s 指物体，a指动作，o指物体。
- 每一个测试样本X_test通过提供在一套支持图片（积极样本）同时提供消极样本`c'=<s,a',o>``c`来捕获概念，
- o和a都是显示给出的，并且依赖于模型的推理能力预测查询图片是否包含测试样本的c概念
- 现存的方法解决Bongard-HOI问题是通过训练在相似任务的集合实现的，因此可以做相似的预测，预测是测试的样本。
- 使用CLIP不需要额外的训练数据，因为CLIP已经学习到了大量视觉概念，自然适配这样的一个任务。

### TPT: Test-Time Prompt Tuning

为什么优化prompt？
- 怎么从预训练模型提取丰富的预训练知识。
    -简单的方法是直接调优模型，不管是端到端还是一个子层，针对输入的一个类。
    - 但是会丢失泛化性能和基础模型的泛化性能
    - prompt在模型之外，不会改变预训练的特征。
- 在这个工作里，我们的目标是使用已经存在的CLIP的知识去提升它的泛化能力。
- 更进一步，我们认为测试时间调优是一种提供模型针对单个样本上下文的方法，有助于刚组精确获得CLIP的知识。








